<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <link rel="canonical" href="https://pakistanaddress.github.io/html/category/article-2344.htm" />
<title>Pytorch中的Conv1d()和Conv2d()函数 - Pakistan Address</title>
<!-- for-mobile-apps -->
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="icon" href="/assets/addons/xcblog/img/pakistanaddress/favicon.ico" type="image/x-icon"/>
<script type="application/x-javascript"> addEventListener("load", function() { setTimeout(hideURLbar, 0); }, false);
		function hideURLbar(){ window.scrollTo(0,1); } </script>
<!-- //for-mobile-apps -->
<link href="/assets/addons/xcblog/css/pakistanaddress/bootstrap.css" rel="stylesheet" type="text/css" media="all" />
<link href="/assets/addons/xcblog/css/pakistanaddress/style.css" rel="stylesheet" type="text/css" media="all" />
<!-- js -->
<script type="text/javascript" src="/assets/addons/xcblog/js/frontend/pakistanaddress/jquery-2.1.4.min.js"></script>
<!-- //js -->
<link href='https://fonts.googleapis.com/css?family=Maven+Pro:400,500,700,900' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic,800,800italic' rel='stylesheet' type='text/css'>
<!-- start-smoth-scrolling -->
<script type="text/javascript">
	jQuery(document).ready(function($) {
		$(".scroll").click(function(event){		
			event.preventDefault();
			$('html,body').animate({scrollTop:$(this.hash).offset().top},1000);
		});
	});
</script>
<!-- start-smoth-scrolling -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?21f4e50ed805b3a1bd1374e6b345c04a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body>
    <!-- header -->
	<div class="header" id="ban">
		<div class="container">
			<div class="w3ls_logo">
								<a href="/">Pakistan Address</a>
							</div>
			<div class="header_right">
			<nav class="navbar navbar-default">
				<!-- Brand and toggle get grouped for better mobile display -->
				<div class="navbar-header">
					<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
				</div>

				<!-- Collect the nav links, forms, and other content for toggling -->
				<div class="collapse navbar-collapse nav-wil" id="bs-example-navbar-collapse-1">
					<nav class="link-effect-7" id="link-effect-7">
						<ul class="nav navbar-nav">
														<li><a href="/">首页</a></li>
														<li><a href="/html/category/">文章分类</a></li>
														<li><a href="#">关于</a></li>
							<li><a href="#">联系</a></li>
						</ul>
					</nav>
				</div>
				<!-- /.navbar-collapse -->
			</nav>
			</div>
			<div class="clearfix"> </div>
		</div>
	</div>
<!-- //header -->
    <!-- about -->
    <div class="about">
        <div class="container">
            <h1 style="word-break: break-all;">Pytorch中的Conv1d()和Conv2d()函数</h1>
            <ul>
                <li><a href="/">首页</a><i>|</i></li>
                <li><a href="/html/category/">文章分类</a><i>|</i></li>
                <li>正文</li>
            </ul>
        </div>
    </div>
    <!-- //about -->
    <!-- single -->
    <div class="single">
        <div class="container">
            <div class="col-md-9">
                <div class="wthree_single_grid1">
                      				  				  				<div id="content_views" class="markdown_views prism-atom-one-dark"> <div class="toc"> <h3>文章目录</h3> <ul> <li> <ul> <li>一、Pytorch中的Conv1d()函数</li> <li>二、Pytorch中的Conv2d()函数</li> <li>三、Pytorch中的MaxPool1d()函数</li> <li>四、pytorch中的MaxPool2d()函数</li> <li>参考资料</li> </ul> </li> </ul> </div> <h2> 一、Pytorch中的Conv1d()函数</h2> <pre><code>class torch.nn.Conv1d( 		in_channels,  		out_channels,  		kernel_size,  		stride=1,  		padding=0,  		dilation=1,  		groups=1,  		bias=True) </code></pre> <p>Conv1d()函数就是利用指定大小的一维卷积核对输入的多通道一维输入信号进行一维卷积操作的卷积层。</p> <p>最简单的情况下，对于输入大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>         C</p> <p>          i</p> <p>          n</p> <p>        ,</p> <p>         L</p> <p>          i</p> <p>          n</p> <p>        )</p> <p>       (N, C_{in}, L_{in})</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，输出大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>         C</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        ,</p> <p>         L</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        )</p> <p>       (N, C_{out}, L_{out})</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的一维卷积层，其中， N 代表batch size，C代表通道的数量, L代表信号序列的长度。</p> <p><img decoding="async" src="http://img.555519.xyz/uploads/20221225/957f0702588cdd2e68705f79881824eb.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"></p> <ul> <li> <b> in_channels (int) </b>– 输入通道个数。在文本应用中，即为词向量的维度</li> <li> <b>out_channels (int) </b>– 输出通道个数 。有多少个out_channels，就需要多少个一维卷积（也就是卷积核的数量）</li> <li> <b>kernel_size(int or tuple)</b> – 卷积核的尺寸；卷积核的第二个维度由in_channels决定，所以实际上卷积核的大小为kernel_size * in_channels</li> <li>stride (int or tuple, optional) – 卷积操作的步长。 默认：1</li> <li>padding (int or tuple, optional) – 输入数据各维度各边上要补齐0的层数。 默认： 0</li> <li>dilation (int or tuple, optional) – 卷积核各元素之间的距离。 默认： 1</li> <li>groups (int, optional) – 输入通道与输出通道之间相互隔离的连接的个数。 默认：1</li> <li>bias (bool, optional) – 如果被置为True，向输出增加一个偏差量，此偏差是可学习参数。 默认：True</li> </ul> <table> <tbody> <tr> <td bgcolor="#FFF0AA" align="left"> <font color="red">一般来说，一维卷积nn.Conv1d()用于文本数据，<u><b>只对宽度进行卷积，对高度不卷积</b></u>。通常，输入大小为<b>word_embedding_dim * max_sent_length</b>，其中，<b>word_embedding_dim</b>为词向量的维度，<b>max_sent_length</b>为句子的最大长度。卷积核窗口在句子长度的方向上滑动，进行卷积操作。</font> </td> </tr> </tbody> </table> <p><strong>示例：</strong><br /> 输入：批大小为50，句子的最大长度为35，词向量维度为300<br /> 目标：句子分类，共2类</p> <pre><code class="prism language-python"><span class="token keyword">import</span> torch <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn  <span class="token comment"># max_sent_len=35, batch_size=50, embedding_size=300</span> conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span> <span class="token comment"># batch_size x max_sent_len x embedding_size -> batch_size x embedding_size x max_sent_len</span> <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input:"</span><span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> output <span class="token operator">=</span> conv1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"output:"</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 最大池化</span> pool1d <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">35</span><span class="token operator">-</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> pool1d_value <span class="token operator">=</span> pool1d<span class="token punctuation">(</span>output<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最大池化输出："</span><span class="token punctuation">,</span> pool1d_value<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 全连接</span> fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> fc_inp <span class="token operator">=</span> pool1d_value<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> pool1d_value<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"全连接输入："</span><span class="token punctuation">,</span> fc_inp<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> fc_outp <span class="token operator">=</span> fc<span class="token punctuation">(</span>fc_inp<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"全连接输出："</span><span class="token punctuation">,</span> fc_outp<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># softmax</span> m <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span> out <span class="token operator">=</span> m<span class="token punctuation">(</span>fc_outp<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输出结果值："</span><span class="token punctuation">,</span> out<span class="token punctuation">)</span> </code></pre> <p>运行结果为：<br /><img decoding="async" src="http://img.555519.xyz/uploads/20221225/0bd326ce4a94c7cb1f7a271a4057c5e7.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"></p> <ul> <li>原始输入大小为(50, 35, 300)，经过permute(0, 2, 1)操作后，输入的大小变为(50, 300, 35)；</li> <li>使用1个window_size为3的卷积核进行卷积，因为一维卷积是在最后维度上扫的，最后output的大小即为：50*100*（35-3+1）=50*100*33</li> <li>output经过最大池化操作后，得到了数据维度为：(50,100,1)</li> <li>经过（输入特征=100，输出特征=2）的全连接层，数据维度就变为了：(50，2)</li> <li>再经过softmax函数就得到了属于两个类别的概率值</li> </ul> <h2> 二、Pytorch中的Conv2d()函数</h2> <pre><code>class torch.nn.Conv2d( 	in_channels,  	out_channels,  	kernel_size,  	stride=1,  	padding=0,  	dilation=1,  	groups=1,  	bias=True)  </code></pre> <p>该函数是利用指定大小的二维卷积核对输入的多通道二维输入信号进行二维卷积操作的卷积层。</p> <p>在最简单的情况下，对于输入大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>         C</p> <p>          i</p> <p>          n</p> <p>        ,</p> <p>        H</p> <p>        ,</p> <p>        W</p> <p>        )</p> <p>       (N, C_{in}, H, W)</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mclose">)</span></span></span></span></span>，输出大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>         C</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        ,</p> <p>         H</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        ,</p> <p>         W</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        )</p> <p>       (N, C_{out}, H_{out}, W_{out})</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.08125em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的二维维卷积层，其卷积计算过程可以如下表述：</p> <p><img decoding="async" src="http://img.555519.xyz/uploads/20221225/0f657545269a947675629da1544cd975.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"><br /><span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        N</p> <p>       N</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span></span></span></span></span> is a batch size, 代表通道的数量, <span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        H</p> <p>       H</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span></span></span></span></span>是输入的二维数据的像素高度， <span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        W</p> <p>       W</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span></span></span></span></span>是输入的二维数据的像素宽度。</p> <p>如果要用二维卷积来实现文本的处理也是可以的，还是上面的那个任务，用二维卷积来做的话，代码如下所示：</p> <pre><code class="prism language-python"><span class="token keyword">import</span> torch <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F  <span class="token comment"># max_sent_len=35, batch_size=50, embedding_dim=300</span> conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># batch_size x 1 × max_sent_len x embedding_dim</span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input:"</span><span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> output <span class="token operator">=</span> conv2<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token comment"># batch_size × kernel_num × H × 1，其中H=max_sent_len-kernel_size+1</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"output:"</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 最大池化</span> <span class="token comment"># pool = nn.MaxPool1d(kernel_size=35-3+1)</span> output <span class="token operator">=</span> output<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> pool1d_value <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool1d<span class="token punctuation">(</span>output<span class="token punctuation">,</span> output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最大池化输出："</span><span class="token punctuation">,</span> pool1d_value<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 全连接</span> fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> fc_inp <span class="token operator">=</span> pool1d_value<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> pool1d_value<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"全连接输入："</span><span class="token punctuation">,</span> fc_inp<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> fc_outp <span class="token operator">=</span> fc<span class="token punctuation">(</span>fc_inp<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"全连接输出："</span><span class="token punctuation">,</span> fc_outp<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># softmax</span> out <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>fc_outp<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"输出结果值："</span><span class="token punctuation">,</span> out<span class="token punctuation">)</span> </code></pre> <p>运行结果如下：<br /><img decoding="async" src="http://img.555519.xyz/uploads/20221225/e18f92ea018c0be01eaf46a2d458f7bc.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"></p> <ul> <li>二维卷积输入大小为(50, 1，35, 300)，</li> <li>使用1个window_size为3的卷积核进行二维卷积，最后output的大小即为：50*100*（35-3+1）*1=50*100*33*1</li> <li>output经过最大池化操作后，得到了数据维度为：(50,100,1)</li> <li>经过（输入特征=100，输出特征=2）的全连接层，数据维度就变为了：(50，2)</li> <li>再经过softmax函数就得到了属于两个类别的概率值</li> </ul> <h2> 三、Pytorch中的MaxPool1d()函数</h2> <pre><code>class torch.nn.MaxPool1d( 	kernel_size,  	stride=None,  	padding=0,  	dilation=1,  	return_indices=False,  	ceil_mode=False) </code></pre> <p>该函数对输入的多通道信号执行一维最大池化操作。<br /> 最简单的情况下，对于输入大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>        C</p> <p>        ,</p> <p>         L</p> <p>          i</p> <p>          n</p> <p>        )</p> <p>       (N, C, L_{in})</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> ，输出大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>        C</p> <p>        ,</p> <p>         L</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        )</p> <p>       (N, C, L_{out})</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 的池化操作，此池化过程可表述如下：<br /><img decoding="async" src="http://img.555519.xyz/uploads/20221225/a6119fef63fdea3021455474c45dfb3f.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"><br /><strong>参数说明:</strong></p> <ul> <li>kernel_size – 最大池化操作的滑动窗大小</li> <li>stride – 滑动窗的步长，默认值是 kernel_size</li> <li>padding – 要在输入信号的各维度各边上要补齐0的层数</li> <li>dilation – 滑动窗中各元素之间的距离</li> <li>return_indices – 如果此参数被设置为True， 那么此池化层在返回输出信号的同时还会返回一连串滑动窗最大值的索引位置，即每个滑动窗的最大值位置信息。这些信息可以在后面的上采样torch.nn.MaxUnpool1d中被用到。</li> <li>ceil_mode – 如果此参数被设置为True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作<br /><img decoding="async" src="http://img.555519.xyz/uploads/20221225/98abd15a58ffcc0b80de75876638ecc7.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"> </li> </ul> <h2> 四、pytorch中的MaxPool2d()函数</h2> <pre><code>class torch.nn.MaxPool2d( 	kernel_size,  	stride=None,  	padding=0,  	dilation=1,  	return_indices=False,  	ceil_mode=False)  </code></pre> <p>该函数是对输入的多通道信号执行二维最大池化操作。</p> <p>最简单的情况下，对于输入大小为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>        C</p> <p>        ,</p> <p>        H</p> <p>        ,</p> <p>        W</p> <p>        )</p> <p>       (N, C, H, W)</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mclose">)</span></span></span></span></span> ，输出大小为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        N</p> <p>        ,</p> <p>        C</p> <p>        ,</p> <p>         H</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        ,</p> <p>         W</p> <p>          o</p> <p>          u</p> <p>          t</p> <p>        )</p> <p>       (N, C, H_{out}, W_{out})</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.08125em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，kernel_size为<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p> <p>        (</p> <p>        k</p> <p>        H</p> <p>        ,</p> <p>        k</p> <p>        W</p> <p>        )</p> <p>       (kH, kW)</p> <p>    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mclose">)</span></span></span></span></span>的池化操作.<br /><img decoding="async" src="http://img.555519.xyz/uploads/20221225/a34b787c0590e5065900e62ddc533224.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"><br /> 示例：</p> <pre><code class="prism language-python"><span class="token keyword">import</span> torch <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn <span class="token comment"># pool of square window of size=3, stride=2</span> <span class="token comment"># m = nn.MaxPool2d(3, stride=2)</span> <span class="token comment"># pool of non-square window</span> m <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> output <span class="token operator">=</span> m<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> </code></pre> <p>运行结果：<br /><img decoding="async" src="http://img.555519.xyz/uploads/20221225/15f3f6e5218268cfcd4d0b3cfd2343b0.jpg" alt="Pytorch中的Conv1d()和Conv2d()函数"></p> <h2> 参考资料</h2> <ul> <li>pytorch中文文档： https://pytorch.apachecn.org/docs/1.2/nn.html#conv1d </li> <li>博客：https://www.jianshu.com/p/45a26d278473 </li> </ul> </div> 			                </div>
                <div class="col-md-12 mt-5">
                                        <p>上一个：<a href="/html/category/article-2343.htm">submodule + gradle配置实现动态打包</a></p>
                                        <p>下一个：<a href="/html/category/article-2345.htm">Tomcat 部署 Web项目以及更改项目名</a></p>
                                    </div>
                            </div>
            <div class="col-md-3">
                <div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/html/category/article-6906.htm" title="动物疫苗存放标语图片大全（动物疫苗未冷藏几小时失效）">动物疫苗存放标语图片大全（动物疫苗未冷藏几小时失效）</a></li>
                        <li class="py-2"><a href="/html/category/article-7504.htm" title="生物质燃料颗粒好卖吗（生物燃料颗粒前景）">生物质燃料颗粒好卖吗（生物燃料颗粒前景）</a></li>
                        <li class="py-2"><a href="/html/category/article-7551.htm" title="宁波安安宠医康丽宠物医院（北仑安安宠物医院）">宁波安安宠医康丽宠物医院（北仑安安宠物医院）</a></li>
                        <li class="py-2"><a href="/html/category/article-6165.htm" title="哪里有免费给狗狗打疫苗的地方重庆（重庆哪里可以免费给狗狗打狂犬疫苗）">哪里有免费给狗狗打疫苗的地方重庆（重庆哪里可以免费给狗狗打狂犬疫苗）</a></li>
                        <li class="py-2"><a href="/html/category/article-6861.htm" title="小孩不知道是不是被猫抓伤需要***吗（不确定小孩是不是被猫抓了能打狂犬疫苗）">小孩不知道是不是被猫抓伤需要***吗（不确定小孩是不是被猫抓了能打狂犬疫苗）</a></li>
                        <li class="py-2"><a href="/html/category/article-6208.htm" title="网络迷踪是恐怖片吗（弹窗惊魂）">网络迷踪是恐怖片吗（弹窗惊魂）</a></li>
                        <li class="py-2"><a href="/html/category/article-7228.htm" title="中国动物疫苗生产企业排名前十（国内动物疫苗生产企业有多少家）">中国动物疫苗生产企业排名前十（国内动物疫苗生产企业有多少家）</a></li>
                        <li class="py-2"><a href="/html/category/article-7458.htm" title="开宠物店靠什么赚钱（开宠物店挣钱么）">开宠物店靠什么赚钱（开宠物店挣钱么）</a></li>
                        <li class="py-2"><a href="/html/category/article-6860.htm" title="济南宠物领养微信群 济南宠物领养微信群号">济南宠物领养微信群 济南宠物领养微信群号</a></li>
                        <li class="py-2"><a href="/html/category/article-6676.htm" title="车险哪个品牌好(车险哪个品牌好一些)">车险哪个品牌好(车险哪个品牌好一些)</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">26</span> <a href="/html/date/2024-08/" title="2024-08 归档">2024-08</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-07/" title="2024-07 归档">2024-07</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">60</span> <a href="/html/date/2024-06/" title="2024-06 归档">2024-06</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-05/" title="2024-05 归档">2024-05</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">60</span> <a href="/html/date/2024-04/" title="2024-04 归档">2024-04</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-03/" title="2024-03 归档">2024-03</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">44</span> <a href="/html/date/2024-02/" title="2024-02 归档">2024-02</a></h4>
            </li>
                    </ul>
    </div>
</div>

            </div>
        </div>
    </div>
    <!-- //single -->
    <!-- footer -->
	
	<div class="copy-right-social">
		<div class="container">
			<div class="footer-pos">
				<a href="#ban" class="scroll"><img src="/assets/addons/xcblog/img/pakistanaddress/arrow.png" alt=" " class="img-responsive" /></a>
			</div>
            <div class="col-lg-8 footer-left">
                <p class="m-0">Pakistan Address 版权所有</p>
            </div>
			<div class="copy-right-social1">
				<div class="w3l_social_icons w3l_social_icons1">
					<ul>
						<li><a href="#" class="facebook"></a></li>
						<li><a href="#" class="twitter"></a></li>
						<li><a href="#" class="google_plus"></a></li>
						<li><a href="#" class="pinterest"></a></li>
						<li><a href="#" class="instagram"></a></li>
					</ul>
				</div>
			</div>
			<div class="clearfix"> </div>
		</div>
	</div>
<!-- //footer -->
<!-- for bootstrap working -->
	<script src="/assets/addons/xcblog/js/frontend/pakistanaddress/bootstrap.js"></script>
    <script>
    $(function() {
        $('.js_to').click(function() {
            var url = $(this).data('url');
            var code = $(this).data('code');
            url += code;

            window.open(url);
        })
    });
    </script>
</body>

</html>